{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-13T12:58:21.634071Z",
     "iopub.status.busy": "2021-07-13T12:58:21.633496Z",
     "iopub.status.idle": "2021-07-13T12:58:29.388008Z",
     "shell.execute_reply": "2021-07-13T12:58:29.386876Z",
     "shell.execute_reply.started": "2021-07-13T12:58:21.633933Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import expand_dims\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Input, Lambda\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T12:59:24.294718Z",
     "iopub.status.busy": "2021-07-13T12:59:24.294304Z",
     "iopub.status.idle": "2021-07-13T12:59:36.795115Z",
     "shell.execute_reply": "2021-07-13T12:59:36.793892Z",
     "shell.execute_reply.started": "2021-07-13T12:59:24.294685Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install imutils\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "create subset of clients\n",
    "\n",
    "- increase comm rounds 300\n",
    "- increase hidden units 400\n",
    "- increase no of layers\n",
    "- no of clients 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T12:59:36.797862Z",
     "iopub.status.busy": "2021-07-13T12:59:36.797400Z",
     "iopub.status.idle": "2021-07-13T12:59:36.806834Z",
     "shell.execute_reply": "2021-07-13T12:59:36.805691Z",
     "shell.execute_reply.started": "2021-07-13T12:59:36.797815Z"
    }
   },
   "outputs": [],
   "source": [
    "debug = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T12:59:36.811667Z",
     "iopub.status.busy": "2021-07-13T12:59:36.811327Z",
     "iopub.status.idle": "2021-07-13T12:59:36.835727Z",
     "shell.execute_reply": "2021-07-13T12:59:36.834192Z",
     "shell.execute_reply.started": "2021-07-13T12:59:36.811636Z"
    }
   },
   "outputs": [],
   "source": [
    "def load(paths, verbose=-1):\n",
    "    '''expects images for each class in seperate dir, \n",
    "    e.g all digits in 0 class in the directory named 0 '''\n",
    "    data = list()\n",
    "    labels = list()\n",
    "    # loop over the input images\n",
    "    for (i, imgpath) in enumerate(paths):\n",
    "        # load the image and extract the class labels        \n",
    "        im_gray = cv2.imread(imgpath , cv2.IMREAD_GRAYSCALE)\n",
    "        image = np.array(im_gray).flatten() # cv2.imread(imgpath) \n",
    "        # print(image.shape)\n",
    "        #label = imgpath.split(os.path.sep)[-2]\n",
    "        label = imgpath.split(os.path.sep)\n",
    "        # scale the image to [0, 1] and add to list\n",
    "        data.append(image/255)\n",
    "        labels.append(label)\n",
    "        # show an update every `verbose` images\n",
    "        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
    "            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n",
    "    # return a tuple of the data and labels\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    random.shuffle(data)  # <- IID\n",
    "    \n",
    "    # sort data for non-iid\n",
    "#     max_y = np.argmax(label_list, axis=-1)\n",
    "#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
    "#     data = [(x,y) for _,y,x in sorted_zip]\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} \n",
    "\n",
    "\n",
    "def batch_data(data_shard, bs=32):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n",
    "\n",
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    \n",
    "    \n",
    "    if debug:\n",
    "        print('global_count', global_count, 'local_count', local_count, 'bs', bs)\n",
    "    \n",
    "    return local_count/global_count\n",
    "\n",
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n",
    "\n",
    "\n",
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "        \n",
    "    return avg_grad\n",
    "\n",
    "\n",
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(200, input_shape=(shape,)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(200))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T12:59:36.839213Z",
     "iopub.status.busy": "2021-07-13T12:59:36.838298Z",
     "iopub.status.idle": "2021-07-13T12:59:36.850403Z",
     "shell.execute_reply": "2021-07-13T12:59:36.849113Z",
     "shell.execute_reply.started": "2021-07-13T12:59:36.839164Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "     @staticmethod    \n",
    "     def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(shape[0], shape[1], shape[2])))\n",
    "        model.add(Lambda(lambda x: expand_dims(x, axis=-1)))\n",
    "        model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D())\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32))\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./input/testSample/img_1.jpg',\n",
       " './input/testSample/img_10.jpg',\n",
       " './input/testSample/img_100.jpg',\n",
       " './input/testSample/img_101.jpg',\n",
       " './input/testSample/img_102.jpg',\n",
       " './input/testSample/img_103.jpg',\n",
       " './input/testSample/img_104.jpg',\n",
       " './input/testSample/img_105.jpg',\n",
       " './input/testSample/img_106.jpg',\n",
       " './input/testSample/img_107.jpg',\n",
       " './input/testSample/img_108.jpg',\n",
       " './input/testSample/img_109.jpg',\n",
       " './input/testSample/img_11.jpg',\n",
       " './input/testSample/img_110.jpg',\n",
       " './input/testSample/img_111.jpg',\n",
       " './input/testSample/img_112.jpg',\n",
       " './input/testSample/img_113.jpg',\n",
       " './input/testSample/img_114.jpg',\n",
       " './input/testSample/img_115.jpg',\n",
       " './input/testSample/img_116.jpg',\n",
       " './input/testSample/img_117.jpg',\n",
       " './input/testSample/img_118.jpg',\n",
       " './input/testSample/img_119.jpg',\n",
       " './input/testSample/img_12.jpg',\n",
       " './input/testSample/img_120.jpg',\n",
       " './input/testSample/img_121.jpg',\n",
       " './input/testSample/img_122.jpg',\n",
       " './input/testSample/img_123.jpg',\n",
       " './input/testSample/img_124.jpg',\n",
       " './input/testSample/img_125.jpg',\n",
       " './input/testSample/img_126.jpg',\n",
       " './input/testSample/img_127.jpg',\n",
       " './input/testSample/img_128.jpg',\n",
       " './input/testSample/img_129.jpg',\n",
       " './input/testSample/img_13.jpg',\n",
       " './input/testSample/img_130.jpg',\n",
       " './input/testSample/img_131.jpg',\n",
       " './input/testSample/img_132.jpg',\n",
       " './input/testSample/img_133.jpg',\n",
       " './input/testSample/img_134.jpg',\n",
       " './input/testSample/img_135.jpg',\n",
       " './input/testSample/img_136.jpg',\n",
       " './input/testSample/img_137.jpg',\n",
       " './input/testSample/img_138.jpg',\n",
       " './input/testSample/img_139.jpg',\n",
       " './input/testSample/img_14.jpg',\n",
       " './input/testSample/img_140.jpg',\n",
       " './input/testSample/img_141.jpg',\n",
       " './input/testSample/img_142.jpg',\n",
       " './input/testSample/img_143.jpg',\n",
       " './input/testSample/img_144.jpg',\n",
       " './input/testSample/img_145.jpg',\n",
       " './input/testSample/img_146.jpg',\n",
       " './input/testSample/img_147.jpg',\n",
       " './input/testSample/img_148.jpg',\n",
       " './input/testSample/img_149.jpg',\n",
       " './input/testSample/img_15.jpg',\n",
       " './input/testSample/img_150.jpg',\n",
       " './input/testSample/img_151.jpg',\n",
       " './input/testSample/img_152.jpg',\n",
       " './input/testSample/img_153.jpg',\n",
       " './input/testSample/img_154.jpg',\n",
       " './input/testSample/img_155.jpg',\n",
       " './input/testSample/img_156.jpg',\n",
       " './input/testSample/img_157.jpg',\n",
       " './input/testSample/img_158.jpg',\n",
       " './input/testSample/img_159.jpg',\n",
       " './input/testSample/img_16.jpg',\n",
       " './input/testSample/img_160.jpg',\n",
       " './input/testSample/img_161.jpg',\n",
       " './input/testSample/img_162.jpg',\n",
       " './input/testSample/img_163.jpg',\n",
       " './input/testSample/img_164.jpg',\n",
       " './input/testSample/img_165.jpg',\n",
       " './input/testSample/img_166.jpg',\n",
       " './input/testSample/img_167.jpg',\n",
       " './input/testSample/img_168.jpg',\n",
       " './input/testSample/img_169.jpg',\n",
       " './input/testSample/img_17.jpg',\n",
       " './input/testSample/img_170.jpg',\n",
       " './input/testSample/img_171.jpg',\n",
       " './input/testSample/img_172.jpg',\n",
       " './input/testSample/img_173.jpg',\n",
       " './input/testSample/img_174.jpg',\n",
       " './input/testSample/img_175.jpg',\n",
       " './input/testSample/img_176.jpg',\n",
       " './input/testSample/img_177.jpg',\n",
       " './input/testSample/img_178.jpg',\n",
       " './input/testSample/img_179.jpg',\n",
       " './input/testSample/img_18.jpg',\n",
       " './input/testSample/img_180.jpg',\n",
       " './input/testSample/img_181.jpg',\n",
       " './input/testSample/img_182.jpg',\n",
       " './input/testSample/img_183.jpg',\n",
       " './input/testSample/img_184.jpg',\n",
       " './input/testSample/img_185.jpg',\n",
       " './input/testSample/img_186.jpg',\n",
       " './input/testSample/img_187.jpg',\n",
       " './input/testSample/img_188.jpg',\n",
       " './input/testSample/img_189.jpg',\n",
       " './input/testSample/img_19.jpg',\n",
       " './input/testSample/img_190.jpg',\n",
       " './input/testSample/img_191.jpg',\n",
       " './input/testSample/img_192.jpg',\n",
       " './input/testSample/img_193.jpg',\n",
       " './input/testSample/img_194.jpg',\n",
       " './input/testSample/img_195.jpg',\n",
       " './input/testSample/img_196.jpg',\n",
       " './input/testSample/img_197.jpg',\n",
       " './input/testSample/img_198.jpg',\n",
       " './input/testSample/img_199.jpg',\n",
       " './input/testSample/img_2.jpg',\n",
       " './input/testSample/img_20.jpg',\n",
       " './input/testSample/img_200.jpg',\n",
       " './input/testSample/img_201.jpg',\n",
       " './input/testSample/img_202.jpg',\n",
       " './input/testSample/img_203.jpg',\n",
       " './input/testSample/img_204.jpg',\n",
       " './input/testSample/img_205.jpg',\n",
       " './input/testSample/img_206.jpg',\n",
       " './input/testSample/img_207.jpg',\n",
       " './input/testSample/img_208.jpg',\n",
       " './input/testSample/img_209.jpg',\n",
       " './input/testSample/img_21.jpg',\n",
       " './input/testSample/img_210.jpg',\n",
       " './input/testSample/img_211.jpg',\n",
       " './input/testSample/img_212.jpg',\n",
       " './input/testSample/img_213.jpg',\n",
       " './input/testSample/img_214.jpg',\n",
       " './input/testSample/img_215.jpg',\n",
       " './input/testSample/img_216.jpg',\n",
       " './input/testSample/img_217.jpg',\n",
       " './input/testSample/img_218.jpg',\n",
       " './input/testSample/img_219.jpg',\n",
       " './input/testSample/img_22.jpg',\n",
       " './input/testSample/img_220.jpg',\n",
       " './input/testSample/img_221.jpg',\n",
       " './input/testSample/img_222.jpg',\n",
       " './input/testSample/img_223.jpg',\n",
       " './input/testSample/img_224.jpg',\n",
       " './input/testSample/img_225.jpg',\n",
       " './input/testSample/img_226.jpg',\n",
       " './input/testSample/img_227.jpg',\n",
       " './input/testSample/img_228.jpg',\n",
       " './input/testSample/img_229.jpg',\n",
       " './input/testSample/img_23.jpg',\n",
       " './input/testSample/img_230.jpg',\n",
       " './input/testSample/img_231.jpg',\n",
       " './input/testSample/img_232.jpg',\n",
       " './input/testSample/img_233.jpg',\n",
       " './input/testSample/img_234.jpg',\n",
       " './input/testSample/img_235.jpg',\n",
       " './input/testSample/img_236.jpg',\n",
       " './input/testSample/img_237.jpg',\n",
       " './input/testSample/img_238.jpg',\n",
       " './input/testSample/img_239.jpg',\n",
       " './input/testSample/img_24.jpg',\n",
       " './input/testSample/img_240.jpg',\n",
       " './input/testSample/img_241.jpg',\n",
       " './input/testSample/img_242.jpg',\n",
       " './input/testSample/img_243.jpg',\n",
       " './input/testSample/img_244.jpg',\n",
       " './input/testSample/img_245.jpg',\n",
       " './input/testSample/img_246.jpg',\n",
       " './input/testSample/img_247.jpg',\n",
       " './input/testSample/img_248.jpg',\n",
       " './input/testSample/img_249.jpg',\n",
       " './input/testSample/img_25.jpg',\n",
       " './input/testSample/img_250.jpg',\n",
       " './input/testSample/img_251.jpg',\n",
       " './input/testSample/img_252.jpg',\n",
       " './input/testSample/img_253.jpg',\n",
       " './input/testSample/img_254.jpg',\n",
       " './input/testSample/img_255.jpg',\n",
       " './input/testSample/img_256.jpg',\n",
       " './input/testSample/img_257.jpg',\n",
       " './input/testSample/img_258.jpg',\n",
       " './input/testSample/img_259.jpg',\n",
       " './input/testSample/img_26.jpg',\n",
       " './input/testSample/img_260.jpg',\n",
       " './input/testSample/img_261.jpg',\n",
       " './input/testSample/img_262.jpg',\n",
       " './input/testSample/img_263.jpg',\n",
       " './input/testSample/img_264.jpg',\n",
       " './input/testSample/img_265.jpg',\n",
       " './input/testSample/img_266.jpg',\n",
       " './input/testSample/img_267.jpg',\n",
       " './input/testSample/img_268.jpg',\n",
       " './input/testSample/img_269.jpg',\n",
       " './input/testSample/img_27.jpg',\n",
       " './input/testSample/img_270.jpg',\n",
       " './input/testSample/img_271.jpg',\n",
       " './input/testSample/img_272.jpg',\n",
       " './input/testSample/img_273.jpg',\n",
       " './input/testSample/img_274.jpg',\n",
       " './input/testSample/img_275.jpg',\n",
       " './input/testSample/img_276.jpg',\n",
       " './input/testSample/img_277.jpg',\n",
       " './input/testSample/img_278.jpg',\n",
       " './input/testSample/img_279.jpg',\n",
       " './input/testSample/img_28.jpg',\n",
       " './input/testSample/img_280.jpg',\n",
       " './input/testSample/img_281.jpg',\n",
       " './input/testSample/img_282.jpg',\n",
       " './input/testSample/img_283.jpg',\n",
       " './input/testSample/img_284.jpg',\n",
       " './input/testSample/img_285.jpg',\n",
       " './input/testSample/img_286.jpg',\n",
       " './input/testSample/img_287.jpg',\n",
       " './input/testSample/img_288.jpg',\n",
       " './input/testSample/img_289.jpg',\n",
       " './input/testSample/img_29.jpg',\n",
       " './input/testSample/img_290.jpg',\n",
       " './input/testSample/img_291.jpg',\n",
       " './input/testSample/img_292.jpg',\n",
       " './input/testSample/img_293.jpg',\n",
       " './input/testSample/img_294.jpg',\n",
       " './input/testSample/img_295.jpg',\n",
       " './input/testSample/img_296.jpg',\n",
       " './input/testSample/img_297.jpg',\n",
       " './input/testSample/img_298.jpg',\n",
       " './input/testSample/img_299.jpg',\n",
       " './input/testSample/img_3.jpg',\n",
       " './input/testSample/img_30.jpg',\n",
       " './input/testSample/img_300.jpg',\n",
       " './input/testSample/img_301.jpg',\n",
       " './input/testSample/img_302.jpg',\n",
       " './input/testSample/img_303.jpg',\n",
       " './input/testSample/img_304.jpg',\n",
       " './input/testSample/img_305.jpg',\n",
       " './input/testSample/img_306.jpg',\n",
       " './input/testSample/img_307.jpg',\n",
       " './input/testSample/img_308.jpg',\n",
       " './input/testSample/img_309.jpg',\n",
       " './input/testSample/img_31.jpg',\n",
       " './input/testSample/img_310.jpg',\n",
       " './input/testSample/img_311.jpg',\n",
       " './input/testSample/img_312.jpg',\n",
       " './input/testSample/img_313.jpg',\n",
       " './input/testSample/img_314.jpg',\n",
       " './input/testSample/img_315.jpg',\n",
       " './input/testSample/img_316.jpg',\n",
       " './input/testSample/img_317.jpg',\n",
       " './input/testSample/img_318.jpg',\n",
       " './input/testSample/img_319.jpg',\n",
       " './input/testSample/img_32.jpg',\n",
       " './input/testSample/img_320.jpg',\n",
       " './input/testSample/img_321.jpg',\n",
       " './input/testSample/img_322.jpg',\n",
       " './input/testSample/img_323.jpg',\n",
       " './input/testSample/img_324.jpg',\n",
       " './input/testSample/img_325.jpg',\n",
       " './input/testSample/img_326.jpg',\n",
       " './input/testSample/img_327.jpg',\n",
       " './input/testSample/img_328.jpg',\n",
       " './input/testSample/img_329.jpg',\n",
       " './input/testSample/img_33.jpg',\n",
       " './input/testSample/img_330.jpg',\n",
       " './input/testSample/img_331.jpg',\n",
       " './input/testSample/img_332.jpg',\n",
       " './input/testSample/img_333.jpg',\n",
       " './input/testSample/img_334.jpg',\n",
       " './input/testSample/img_335.jpg',\n",
       " './input/testSample/img_336.jpg',\n",
       " './input/testSample/img_337.jpg',\n",
       " './input/testSample/img_338.jpg',\n",
       " './input/testSample/img_339.jpg',\n",
       " './input/testSample/img_34.jpg',\n",
       " './input/testSample/img_340.jpg',\n",
       " './input/testSample/img_341.jpg',\n",
       " './input/testSample/img_342.jpg',\n",
       " './input/testSample/img_343.jpg',\n",
       " './input/testSample/img_344.jpg',\n",
       " './input/testSample/img_345.jpg',\n",
       " './input/testSample/img_346.jpg',\n",
       " './input/testSample/img_347.jpg',\n",
       " './input/testSample/img_348.jpg',\n",
       " './input/testSample/img_349.jpg',\n",
       " './input/testSample/img_35.jpg',\n",
       " './input/testSample/img_350.jpg',\n",
       " './input/testSample/img_36.jpg',\n",
       " './input/testSample/img_37.jpg',\n",
       " './input/testSample/img_38.jpg',\n",
       " './input/testSample/img_39.jpg',\n",
       " './input/testSample/img_4.jpg',\n",
       " './input/testSample/img_40.jpg',\n",
       " './input/testSample/img_41.jpg',\n",
       " './input/testSample/img_42.jpg',\n",
       " './input/testSample/img_43.jpg',\n",
       " './input/testSample/img_44.jpg',\n",
       " './input/testSample/img_45.jpg',\n",
       " './input/testSample/img_46.jpg',\n",
       " './input/testSample/img_47.jpg',\n",
       " './input/testSample/img_48.jpg',\n",
       " './input/testSample/img_49.jpg',\n",
       " './input/testSample/img_5.jpg',\n",
       " './input/testSample/img_50.jpg',\n",
       " './input/testSample/img_51.jpg',\n",
       " './input/testSample/img_52.jpg',\n",
       " './input/testSample/img_53.jpg',\n",
       " './input/testSample/img_54.jpg',\n",
       " './input/testSample/img_55.jpg',\n",
       " './input/testSample/img_56.jpg',\n",
       " './input/testSample/img_57.jpg',\n",
       " './input/testSample/img_58.jpg',\n",
       " './input/testSample/img_59.jpg',\n",
       " './input/testSample/img_6.jpg',\n",
       " './input/testSample/img_60.jpg',\n",
       " './input/testSample/img_61.jpg',\n",
       " './input/testSample/img_62.jpg',\n",
       " './input/testSample/img_63.jpg',\n",
       " './input/testSample/img_64.jpg',\n",
       " './input/testSample/img_65.jpg',\n",
       " './input/testSample/img_66.jpg',\n",
       " './input/testSample/img_67.jpg',\n",
       " './input/testSample/img_68.jpg',\n",
       " './input/testSample/img_69.jpg',\n",
       " './input/testSample/img_7.jpg',\n",
       " './input/testSample/img_70.jpg',\n",
       " './input/testSample/img_71.jpg',\n",
       " './input/testSample/img_72.jpg',\n",
       " './input/testSample/img_73.jpg',\n",
       " './input/testSample/img_74.jpg',\n",
       " './input/testSample/img_75.jpg',\n",
       " './input/testSample/img_76.jpg',\n",
       " './input/testSample/img_77.jpg',\n",
       " './input/testSample/img_78.jpg',\n",
       " './input/testSample/img_79.jpg',\n",
       " './input/testSample/img_8.jpg',\n",
       " './input/testSample/img_80.jpg',\n",
       " './input/testSample/img_81.jpg',\n",
       " './input/testSample/img_82.jpg',\n",
       " './input/testSample/img_83.jpg',\n",
       " './input/testSample/img_84.jpg',\n",
       " './input/testSample/img_85.jpg',\n",
       " './input/testSample/img_86.jpg',\n",
       " './input/testSample/img_87.jpg',\n",
       " './input/testSample/img_88.jpg',\n",
       " './input/testSample/img_89.jpg',\n",
       " './input/testSample/img_9.jpg',\n",
       " './input/testSample/img_90.jpg',\n",
       " './input/testSample/img_91.jpg',\n",
       " './input/testSample/img_92.jpg',\n",
       " './input/testSample/img_93.jpg',\n",
       " './input/testSample/img_94.jpg',\n",
       " './input/testSample/img_95.jpg',\n",
       " './input/testSample/img_96.jpg',\n",
       " './input/testSample/img_97.jpg',\n",
       " './input/testSample/img_98.jpg',\n",
       " './input/testSample/img_99.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Declare path to the MNIST dataset folder\n",
    "img_path = './input/testSample/'\n",
    "\n",
    "# Get the list of image filenames in the directory\n",
    "image_filenames = os.listdir(img_path)\n",
    "\n",
    "# Filter out non-image files (if needed)\n",
    "image_filenames = [filename for filename in image_filenames if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "\n",
    "# Construct the full image paths\n",
    "image_paths = [os.path.join(img_path, filename) for filename in image_filenames]\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_test = LabelBinarizer().fit_transform(y_test)\n",
    "\n",
    "# Optional: Load and preprocess images from the image paths\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imlist(path):\n",
    "    \"\"\"\n",
    "    The function imlist returns all the names of the files in \n",
    "    the directory path supplied as argument to the function.\n",
    "    \"\"\"\n",
    "    return [os.path.join(path, f) for f in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#apply our function\n",
    "image_list, label_list = load(image_paths, verbose=10000)\n",
    "\n",
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "#label_list = lb.fit_transform(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #declear path to your mnist data folder\n",
    "\n",
    "# img_path = './input/trainingSet/trainingSet' #'../input/cifar10-pngs-in-folders/cifar10/test'  # <-- test dataset #'../input/mnistasjpg/trainingSample/trainingSample' # <-- smaller dataset\n",
    "# import os \n",
    "# #get the path list using the path object\n",
    "# image_paths  =  os.listdir(img_path)\n",
    "# image_paths = list(paths.list_images(img_path))\n",
    "\n",
    "# #apply our function\n",
    "# image_list, label_list = load(image_paths, verbose=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-07-13T12:59:46.668278Z",
     "iopub.status.busy": "2021-07-13T12:59:46.667823Z",
     "iopub.status.idle": "2021-07-13T13:05:05.052829Z",
     "shell.execute_reply": "2021-07-13T13:05:05.051642Z",
     "shell.execute_reply.started": "2021-07-13T12:59:46.668247Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y has 0 samples: array([], dtype=float64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#binarize the labels\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lb \u001b[39m=\u001b[39m LabelBinarizer()\n\u001b[1;32m----> 3\u001b[0m label_list \u001b[39m=\u001b[39m lb\u001b[39m.\u001b[39;49mfit_transform(label_list)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:329\u001b[0m, in \u001b[0;36mLabelBinarizer.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, y):\n\u001b[0;32m    310\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit label binarizer/transform multi-class labels to binary labels.\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \n\u001b[0;32m    312\u001b[0m \u001b[39m    The output of transform is sometimes referred to as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39m        will be of CSR format.\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(y)\u001b[39m.\u001b[39mtransform(y)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:303\u001b[0m, in \u001b[0;36mLabelBinarizer.fit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultioutput target data is not supported with label binarization\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my has 0 samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y)\n\u001b[0;32m    305\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparse_input_ \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39missparse(y)\n\u001b[0;32m    306\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m=\u001b[39m unique_labels(y)\n",
      "\u001b[1;31mValueError\u001b[0m: y has 0 samples: array([], dtype=float64)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#binarize the labels\n",
    "lb = LabelBinarizer()\n",
    "label_list = lb.fit_transform(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T13:05:05.055191Z",
     "iopub.status.busy": "2021-07-13T13:05:05.054706Z",
     "iopub.status.idle": "2021-07-13T13:05:05.083818Z",
     "shell.execute_reply": "2021-07-13T13:05:05.082654Z",
     "shell.execute_reply.started": "2021-07-13T13:05:05.055145Z"
    }
   },
   "outputs": [],
   "source": [
    "#split data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_list, \n",
    "                                                    label_list, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T14:30:07.110052Z",
     "iopub.status.busy": "2021-07-13T14:30:07.109651Z",
     "iopub.status.idle": "2021-07-13T14:30:07.119319Z",
     "shell.execute_reply": "2021-07-13T14:30:07.117828Z",
     "shell.execute_reply.started": "2021-07-13T14:30:07.110017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 35, 315, 35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T14:30:07.320814Z",
     "iopub.status.busy": "2021-07-13T14:30:07.320448Z",
     "iopub.status.idle": "2021-07-13T14:30:07.415722Z",
     "shell.execute_reply": "2021-07-13T14:30:07.414583Z",
     "shell.execute_reply.started": "2021-07-13T14:30:07.320781Z"
    }
   },
   "outputs": [],
   "source": [
    "#create clients\n",
    "clients = create_clients(X_train, y_train, num_clients=100, initial='client')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T14:30:07.475360Z",
     "iopub.status.busy": "2021-07-13T14:30:07.474941Z",
     "iopub.status.idle": "2021-07-13T14:30:07.480347Z",
     "shell.execute_reply": "2021-07-13T14:30:07.479094Z",
     "shell.execute_reply.started": "2021-07-13T14:30:07.475327Z"
    }
   },
   "outputs": [],
   "source": [
    "# client_names = ['{}_{}'.format('client', i+1) for i in range(100)]\n",
    "# s = clients['client_1'][0][1]*0\n",
    "# for c in client_names:\n",
    "#     sum = clients[c][0][1]\n",
    "#     for i in range(1,378):\n",
    "#         sum = sum + clients[c][i][1]\n",
    "        \n",
    "#     s = s + sum/378\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T15:04:24.748877Z",
     "iopub.status.busy": "2021-07-13T15:04:24.748503Z",
     "iopub.status.idle": "2021-07-13T15:04:33.484238Z",
     "shell.execute_reply": "2021-07-13T15:04:33.483097Z",
     "shell.execute_reply.started": "2021-07-13T15:04:24.748844Z"
    }
   },
   "outputs": [],
   "source": [
    "#process and batch the training data for each client\n",
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)\n",
    "    \n",
    "#process and batch the test set  \n",
    "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T15:04:33.486700Z",
     "iopub.status.busy": "2021-07-13T15:04:33.486245Z",
     "iopub.status.idle": "2021-07-13T15:04:33.493202Z",
     "shell.execute_reply": "2021-07-13T15:04:33.491691Z",
     "shell.execute_reply.started": "2021-07-13T15:04:33.486654Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "comms_round = 50\n",
    "loss='categorical_crossentropy'\n",
    "metrics = ['accuracy']\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr, \n",
    "                decay=lr / comms_round, \n",
    "                momentum=0.9\n",
    "               )          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T15:04:33.496963Z",
     "iopub.status.busy": "2021-07-13T15:04:33.496054Z",
     "iopub.status.idle": "2021-07-13T15:04:33.542360Z",
     "shell.execute_reply": "2021-07-13T15:04:33.541297Z",
     "shell.execute_reply.started": "2021-07-13T15:04:33.496884Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize global model\n",
    "\n",
    "build_shape = 784 #(28, 28, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n",
    "\n",
    "smlp_global = SimpleMLP()\n",
    "global_model = smlp_global.build(build_shape, 10) \n",
    "global_acc_list = []\n",
    "global_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T15:04:33.544696Z",
     "iopub.status.busy": "2021-07-13T15:04:33.544251Z",
     "iopub.status.idle": "2021-07-13T15:34:50.170268Z",
     "shell.execute_reply": "2021-07-13T15:34:50.169127Z",
     "shell.execute_reply.started": "2021-07-13T15:04:33.544662Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m local_model\u001b[39m.\u001b[39mset_weights(global_weights)\n\u001b[0;32m     33\u001b[0m \u001b[39m#fit local model with client's data\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m local_model\u001b[39m.\u001b[39;49mfit(clients_batched[client], epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     36\u001b[0m \u001b[39m#scale the model weights and add to list\u001b[39;00m\n\u001b[0;32m     37\u001b[0m scaling_factor \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m \u001b[39m# weight_scalling_factor(clients_batched, client)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileifot8xwz.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\ayoub\\OneDrive\\Bureau\\federate\\env\\Lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    all_client_names = list(clients_batched.keys())\n",
    "           \n",
    "    client_names = random.sample(all_client_names, k=10)\n",
    "    # print(client_names, len(client_names))\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "#     if debug: \n",
    "#         # print('all_client_names', all_client_names)\n",
    "#         print('client_names', client_names, len(client_names))\n",
    "                \n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(build_shape, 10)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
    "        # print('scaling_factor', scaling_factor)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_acc_list.append(global_acc)\n",
    "        global_loss_list.append(global_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T15:35:47.454952Z",
     "iopub.status.busy": "2021-07-13T15:35:47.454477Z",
     "iopub.status.idle": "2021-07-13T15:35:47.799876Z",
     "shell.execute_reply": "2021-07-13T15:35:47.798723Z",
     "shell.execute_reply.started": "2021-07-13T15:35:47.454910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IID | total comm rounds 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IID \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(16,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(list(range(0,len(global_loss_list))), global_loss_list)\n",
    "plt.subplot(122)\n",
    "plt.plot(list(range(0,len(global_acc_list))), global_acc_list)\n",
    "print('IID | total comm rounds', len(global_acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-13T15:38:12.630178Z",
     "iopub.status.busy": "2021-07-13T15:38:12.629719Z",
     "iopub.status.idle": "2021-07-13T15:38:12.835156Z",
     "shell.execute_reply": "2021-07-13T15:38:12.834001Z",
     "shell.execute_reply.started": "2021-07-13T15:38:12.630136Z"
    }
   },
   "outputs": [],
   "source": [
    "iid_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\n",
    "iid_df.to_csv('MNIST_IID.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL AVEC CRYPTAGE HOMOMORPHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(local_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PySyft in c:\\users\\ayoub\\onedrive\\bureau\\federate\\env\\lib\\site-packages (0.0.1)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tenseal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtenseal\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mts\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m## Encryption Parameters\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[39m# controls precision of the fractional part\u001b[39;00m\n\u001b[0;32m     10\u001b[0m bits_scale \u001b[39m=\u001b[39m \u001b[39m26\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tenseal'"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install PySyft\n",
    "import random\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import tenseal as ts\n",
    "## Encryption Parameters\n",
    "\n",
    "# controls precision of the fractional part\n",
    "bits_scale = 26\n",
    "\n",
    "# Create TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[31, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, bits_scale, 31]\n",
    ")\n",
    "\n",
    "# set the scale\n",
    "context.global_scale = pow(2, bits_scale)\n",
    "\n",
    "# galois keys are required to do ciphertext rotations\n",
    "context.generate_galois_keys()\n",
    "\n",
    "context = ts.context(\n",
    "            ts.SCHEME_TYPE.CKKS,\n",
    "            poly_modulus_degree=8192,\n",
    "            coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    "          )\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2**40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_parameters(param, context):\n",
    "    \"\"\"\n",
    "    Returns encrypted parameters using Homomorphic Encryption.\n",
    "    Args:\n",
    "        - param (np.ndarray): parameters of a model\n",
    "        - context (tenseal.Context): context for homomorphic encryption\n",
    "    Returns:\n",
    "        - enc_param (tenseal.CKKSTensor): encrypted parameters of the model\n",
    "    \"\"\"\n",
    "    enc_param = ts.ckks_tensor(context, param)\n",
    "    return enc_param\n",
    "\n",
    "def decrypt_parameters(enc_param):\n",
    "    \"\"\"\n",
    "    Decrypts encrypted parameters using Homomorphic Encryption.\n",
    "    Args:\n",
    "        - enc_param (tenseal.CKKSTensor): encrypted parameters of a model\n",
    "    Returns:\n",
    "        - param (np.ndarray): decrypted parameters of the model\n",
    "    \"\"\"\n",
    "    param = enc_param.decrypt()\n",
    "    return param\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comms_round = 100\n",
    "\n",
    "# Setup TenSEAL context\n",
    "context = ts.context(\n",
    "    ts.SCHEME_TYPE.CKKS,\n",
    "    poly_modulus_degree=8192,\n",
    "    coeff_mod_bit_sizes=[60, 40, 40, 60]\n",
    ")\n",
    "context.generate_galois_keys()\n",
    "context.global_scale = 2 ** 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debut cryptage\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "kk\n",
      "fin cryptage\n"
     ]
    }
   ],
   "source": [
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    all_client_names = list(clients_batched.keys())\n",
    "           \n",
    "    client_names = random.sample(all_client_names, k=10)\n",
    "    # print(client_names, len(client_names))\n",
    "    random.shuffle(client_names)\n",
    "    \n",
    "#     if debug: \n",
    "#         # print('all_client_names', all_client_names)\n",
    "#         print('client_names', client_names, len(client_names))\n",
    "                \n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleMLP()\n",
    "        local_model = smlp_local.build(build_shape, 10)\n",
    "        local_model.compile(loss=loss, \n",
    "                      optimizer=optimizer, \n",
    "                      metrics=metrics)\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        local_model.get_weights()\n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
    "        # print('scaling_factor', scaling_factor)\n",
    "        \n",
    "        #code original \n",
    "        \n",
    "        #scale the model weights and add to list\n",
    "       # scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
    "        # print('scaling_factor', scaling_factor)\n",
    "        #scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        #scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        #K.clear_session()\n",
    "      \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    #average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "        loc_weights=local_model.get_weights()\n",
    "        print('debut cryptage')\n",
    "        encrypted_loc_weight = []\n",
    "        for weights in loc_weights[2]:\n",
    "            print('kk')\n",
    "            encrypted_weight= encrypt_parameters(weights, context)\n",
    "            encrypted_loc_weight.append(encrypted_weight)\n",
    "        print('fin cryptage')\n",
    "        scaled_weights = scale_model_weights(encrypted_loc_weight, scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
    "        global_acc_list.append(global_acc)\n",
    "        global_loss_list.append(global_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
